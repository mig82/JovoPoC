# Install Jovo

## 1. Install Jovo

Get the Jovo CLI

    npm install -g jovo-cli

Working with  jovo-cli@3.2.1

## 2. Create a place for voice projects

Create a place in the Visualizer project structure for the voice app or apps.
Let's make that `./voice`.

```
mkdir voice
```

The idea is to end up with this:

```
voice
└── VoiceAppFoo
└── VoiceAppBar
```

## 3. Create a Jovo project

We could call this after the Visualizer project.
**Note:** If we're going to support more than one, we'll have to prompt for a name.

```
cd voice
jovo new JovoPoC
```

This resuls in the following project structure.

```
voice/
└── JovoPoC
    ...
    ├── models
    │   └── en-US.json
	...
    ├── project.js
    ├── src
    │   ├── app.js
    │   ├── config.js
    │   └── index.js
    └── test
```

Where...

**Project Files:**  Anything that is needed to publish a project to voice platforms like Amazon Alexa and Google Assistant.

* project.js - Jovo project config —e.g. which voice platforms are targeted.
* models - Jovo's language model files —one per locale— which then get converted into platform-specific models.
* platforms - Platform-specific files —e.g. One for Google, one for Alexa, etc.

**Source Files:** The logic for the app, meant to be later deployed to hosting providers like AWS Lambda.

* app.js - App Logic. Contains intents, handler logic. The logic should be further broken down into other modules.
* config.js - App Config. Logic-related configuration, intent mapping and local DB.
* index.js - Host Configuration. Everything related to running and hosting the application, either in Lambda or using a webhook (for local prototyping).


## 4. Run the Jovo project locally for development.

Since Visualizer already uses the Jovo Debugger's default port 3000, we must set
the environment varialbe `JOVO_PORT` to tell it where to run instead.
This is also important so that the `npm test` script will look for the debugger
at this port as well.

```
cd JovoPoC
export JOVO_PORT=4000
jovo run
```

Add the `--watch` flag to automatically restart when changes to the app are made.

```
jovo run --watch
```

Alternatively, we could set the variable in code. We'd have to do this in both `app.s`
and the test scripts —e.g. `sample-test.js`— so that testing can find the server.

```
process.env.JOVO_PORT = 4000
```

## 5. Build the Jovo project

Generate the platform specific files for Alexa and Google Assistant.

```
jovo build
```

This generates the `db` and the `platforms` folders.

```
voice/
└── JovoPoC
    ...
	├── db
    │   └── db.json
	...
	├── platforms
    │   ├── alexaSkill
    │   └── googleAction
    ...
```

Jovo advises that the `/platforms` folder should not be versioned. So:

```
echo "/platforms" >> .gitignore
```

## 6. Deploy Alexa Skill

Install and configure the ASK (Alexa Skills Kit) CLI. This will allow the CLI access to the Alexa dev account.

```
npm install -g ask-cli
ask configure
```

**Note:** there's a `--profile` option to create a new profile. We could do something like:

```
ask configure --profile quantum
```

This creates a JSON configuration file with all the profiles at `~/.ask/cli_config`.

For systems without a browser, use:

```
ask configure --no-browser
```

Initialise ASK in the project. This will prompt for the Alexa skill id, the package location (Already generated by Jovo) and the Lambda code path —if we mean to create one. The command is interactive.

```
ask init
? Skill Id (leave empty to create one):  voice-banking
? Skill package path:  ./platforms/alexaSkill/skill-package
? Lambda code path for default region (leave empty to not deploy Lambda):
```

To automate answers for it use the `expect` command.

```
echo '#!/usr/bin/expect
spawn ask init
expect "? Skill Id (leave empty to create one):"
send "quantum-skill\r"
expect "? Skill package path:"
send "./platforms/alexaSkill/skill-package\r"
expect "? Lambda code path for default region (leave empty to not deploy Lambda):"
send "\r"' > ask_init.sh
chmod u+x ask_init.sh
./ask_init.sh
rm ./ask_init.sh

```

**Note:** Piping answers to `ask init` using `|` and `echo`  or `printf` —e.g.:
`printf 'quantum-skill\n./platforms/alexaSkill/skill-package\n\n' | ask init`— won't work.


Deploy using Jovo. The `-p` flag allows to choose a specific platform `-p, --platform=alexaSkill|googleAction|spokestack`

```
jovo deploy --platform=alexaSkill
```

This uploads the voice model to the Alexa Skills and enables the new skill for testing on the linked Amazon account.

Open the [Alexa Dev Console](https://developer.amazon.com/alexa/console/ask) to make sure that the skill is deployed.

To run against a device, again use the `run` command and Ask Alexa to open *"my test app"*.

**IMPORTANT:** Voice models are language-specific, so the Alexa device must be set to use one of the locales for which a voice model has been created.

```
jovo run --port 3301
```

## 7. Deploy Google Assistant (Conversational Actions)

Following instructions from the tutorial found [here](https://www.jovo.tech/tutorials/google-conversational-actions-getting-started)

> Jovo has been offering support for Google Assistant since our launch more than 3 years ago. From the beginning on, we integrated with Google's natural language understanding service Dialogflow, the then standard way to build Google Actions. Although this already worked great (including support for additional integrations), our users had to create and configure a Dialogflow agent as an additional step.
> Recently, Google introduced a new way to build apps for Google Assistant: Conversational Actions. This new release (including their Actions Builder graphical user interace) removed the necessity to connect with Dialogflow for natural language understanding.

Go to the [Conversational Actions Console](https://console.actions.google.com/) and create a custom blank project.

Create a new Jovo project.

```
jovo new JovoPoC --template google-conversational-actions-helloworld --locale en
```

Copy the project's id from the project's settings in the Google Actions Console. It's also the `project_id` in the browser's URL —e.g. `https://console.actions.google.com/project/[project_id]/settings/general`.

Build the Jovo project.

```
jovo build
```

This generates the Google Conversational Actions folder.

```
platforms/
└── googleAction
    ├── actions
    │   └── actions.yaml
    ├── custom
    │   ├── global
    │   │   ├── HelloWorldIntent.yaml
    │   │   ├── MyNameIsIntent.yaml
    │   │   └── actions.intent.MAIN.yaml
    │   ├── intents
    │   │   ├── HelloWorldIntent.yaml
    │   │   └── MyNameIsIntent.yaml
    │   └── types
    │       └── NameInputType.yaml
    ├── manifest.yaml
    ├── settings
    │   └── settings.yaml
    └── webhooks
        └── ActionsOnGoogleFulfillment.yaml
```

Download the GActions CLI OS-specific package and the SHA256 hash from
https://developers.google.com/assistant/actionssdk/gactions#install_the_gactions_command-line_tool

**Note:** There's a zip for Windows, and a gzipped tarball for each MacOS and Linux.

For MacOS:
```
curl -O https://dl.google.com/gactions/v3/release/gactions-sdk_darwin.tar.gz
sha256sum gactions-sdk_darwin.tar.gz
```

Verify the SHA256 hash to check the download's integrity.
```
curl -O https://dl.google.com/gactions/v3/release/gactions-sdk_darwin.tar.gz.sha256
cat gactions-sdk_darwin.tar.gz.sha256
```

Decompress the tarball
```
tar -zxvf gactions-sdk_darwin.tar.gz
```

Add the binary to the `PATH`, give it permissions to execute and check the version.

```
chmod u+x aog_cli/gactions
export PATH=$PATH:"/Applications/GActions/aog_cli"
gactions version
```

Connect the gactions CLI to your Google account. This will fire up the browser and prompt you to grant Google Actions CLI access to your Goolge Account.

```
gactions login
```

**Note:** This is a lot like Alexa's `ask configure` command, except there appears to be no `--no-browser` option.

Deploy using Jovo. The `-p` flag allows to choose a specific platform `-p, --platform=alexaSkill|googleAction|spokestack`

```
jovo deploy --platform=googleAction
```

**Note:** The first time around for each project, you will run into:

```
$ jovo deploy

 jovo deploy: Deploys the project to the voice platform.
   >> Learn more: https://jovo.tech/docs/cli/deploy

  ✖ Deploying Conversational Action
 ›   Error: There was a problem:
 ›
 ›   [ERR] Actions API has not been used in project xyz before or it is disabled. Enable it
 ›    by visiting https://console.developers.google.com/apis/api/actions.googleapis.com/overview?project=xyz then retry. If you enabled this API recently, wait a few minutes for the
 ›   action to propagate to our systems and retry.
 ›   
 ›   Module:   jovo-cli-platform-google-ca
 ›
```

Navigate to https://console.developers.google.com/apis/api/actions.googleapis.com/overview?project=xyz and click the button to **Actions API**

Run the Jovo local development server

```
jovo run --port 3301
```

## Potential Demos

* Balances and enquiring on specific transaction types
	* What's my balance? current or savings? savings.
	* What's the balance on my card? When is my card due?
	* Did I get my payroll yet?
* PFM
	* Set a monthly budget for leisure/entertainment
	* What's my budget for leisure this month?
* Payments
	* Send 20 EUR to Matt? Matt Terry or Matt Trevathan? Trevathan. From the usual account? yes.
* Investment
	* How's my stock/portfolio doing? Your portfolio is up/down 7% this month. Would you like to hear today's advice on your existing stock?
* Make a special request for something not supported
	* Ask my bank advisor whether XYZ. -> Raise a support ticket with the transcript of the voice note.

## Predefined bits and pieces we can ship

* Intents
	* on_yes
	* on_no
	* on_back(global)
* types
	* Currency
	* First name
	* Last name
	* Email address
	* Phone number
* Scenes
	* Send information to an email or mobile device —e.g. transaction queries, transaction details, card extracts
	* Ask about satisfaction + as for feedback + ask to rate us
	* Continue from phone
	*

## Reconfiguration

Jovo offers an option to create different configurations per environment by using a naming convention on the `config.js` file —e.g.:

* `config.js`: Default config of the project
* `config.qa.js`: Config overrides for the QA environment (e.g. DynamoDB)
* `config.prod.js`: Config overrides for the production environment (e.g. DynamoDB + Analytics)

Read more [here](https://www.jovo.tech/docs/config-js#staging)

## Internationalisation

Jovo can use i18n's per locale in the models folder.

However, it seems that where Alexa supports models per country, Google Assistant only supports them per country. So where Alexa will pick up `en-US.json`, Google Assistant will only recognise `en.json`.

https://youtu.be/cJZAT0JLABs

## To Do:

The following are areas where we still need to research how best leverage Jovo capabilities.

* Unit testing:
 * https://www.jovo.tech/templates/unit-testing
 * https://youtu.be/zmrgPNOeXgk


## Questions

1. Where should we create the Jovo project within the Vis project? Would `/voice` be adequate? Placing it under `/forms` seems off. However, voice apps can leverage UI designs for scenarios where they're bundled inside a screen app —the way [Botsociety](https://botsociety.io) does it.

2. Though the Jovo CLI does not yet support automatic deployment to **DialogFlow** (Agent creation is still manual), Google has introduced support for doing this programmatically via a REST API. See https://cloud.google.com/dialogflow/es/docs/reference/rest/v2/projects.agent/restore. Should we leverage this as a plugin/extension of our own? Or do we wait for Jovo to introduce it?

3. Can we build the demo as a collection of conversational components that can be mashed together?

4. For Google's Conversational Actions, can the project be created via API or CLI? [This](https://youtu.be/IKoyKMKTHag) video refers to the existence of a CLI and SDK.

5. Google's `gaction login` command does not appear to have a `--no-browser` option. How do we set this up to build in CI?

6. Jovo can also integrate with other platforms. Do we have an interest in these?

7. Could we keep session state in Fabric? Keeping session state in Google Actions is cumbersome. Some things are stored as `$session.params['slot_name']` and others are stored as `$intent.params.['currency_from']`. It's also confusing and inconsistent. There's a `$intent.params.['currency_from'].(original|resolved)` but nothing equivalent for `$session.params['slot_name']`.

* [Facebook Messenger](https://www.jovo.tech/marketplace/jovo-platform-facebookmessenger)
* [Samsung Bixby](https://www.jovo.tech/marketplace/jovo-platform-bixby)


# How do we design intents in Visualizer?

In order to create a new intent:

* Create a folder by the name of the intent.
* Create an `index.js`, `start.js`, `slots.js`, `resolve.js`, `again.js`
  * Can we code that just loads this as configuration instead? ie. `start.yaml`, `slots.yaml`, `resolve.yaml`, and `again.yaml`.
* Create a folder called `models` for the voice models of `start` and `resolve` —which are the two global ones.
* Create the models as `en-US.yaml`, `es-ES.yaml`. Each can have a different section `---` for each of `start` and `resolve`.
* When the voice  models are loaded, they must be added to the final model by a name that matches the `start` and `resolve` intents.
* Load the `start` and `again` of each intent as global handlers.
* Add an indicator for the intent to be `public` or not. If public, it won't require a user session.
* Watch the `intents` folder, and every time there's a change, build and copy into the actual Jovo project.
* Create a `types` folder with one YAML file per type.


# NLP.js Integration for Web

**NOTE:** Jovo's v3 integration for using NLP.js as the NLU for the Web platform presents problems when trying to extract basic data types such as `number` —and potentially also `date`. See [this issue](https://github.com/jovotech/jovo-starter-web-standalone/issues/5) on their Github repo. Jovo plans to fix this in the upcoming v4 release, but at the time of writing this, the v4 release is still in Alpha stage.

For the built-in entity (numbers, dates, etc) extraction to work we have to install the `@nlpjs/builtin-default` package and an additional package for each targetted locale —e.g.

```
npm i @nlpjs/builtin-default @nlpjs/lang-en
```

Read: https://github.com/jovotech/jovo-starter-web-standalone/issues/5

Also read NLP.js's docs on adding multiple languages.
https://github.com/axa-group/nlp.js/blob/master/docs/v4/quickstart.md#adding-multilanguage

# Dialogflow Integration for Web

Using [Dialogflow as the NLU](https://www.jovo.tech/marketplace/jovo-nlu-dialogflow) for the Web platform requires the creation of a JSON file inside the `src` directory of the project, and padding the relative path to it as the `credentialsFile` property of the `DialogflowNlu` plugin.

The process of setting up the credentials for the Jovo CLI to deploy Dialogflow models and for the Jovo app to be able to authenticate requests to Dialogflow using this `credentialsFile` is outlined [here](https://www.jovo.tech/tutorials/deploy-dialogflow-agent#step-1:-setting-up-authentication)

The file must look like this:

`src/path/to/dialogflow_service_acct_key.json`
```json
{
	"type": "service_account",
    "project_id": "dialogflow-agent-id",
	"private_key_id": "13177******************************3251e",
	"private_key": "-----BEGIN PRIVATE KEY-----\nMIIEvg...I9+sjSC\n-----END PRIVATE KEY-----\n",
	"client_email": "my-service-account-name@dialogflow-agent-id.iam.gserviceaccount.com",
	"client_id": "11300************1093",
	"auth_uri": "https://accounts.google.com/o/oauth2/auth",
	"token_uri": "https://oauth2.googleapis.com/token",
	"auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
	"client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/my-service-account-name%40dialogflow-agent-id.iam.gserviceaccount.com"
}
```

It can be created from the [Google Cloud Platform's console](https://console.cloud.google.com). You can also get there from the [Dialogflow Console](https://dialogflow.cloud.google.com) by clicking the gear icon next to the Dialogflow Agent's name, and then clicking the `Project ID` from the `General` tab.

Once in the GCP Console, search for [IAM Permissions](https://console.cloud.google.com/iam-admin), go to [Service Accounts](https://console.cloud.google.com/iam-admin/serviceaccounts?project=jovopoc-p9by), create a new **Service Account**, create a new **key** for it and assign it the ***Dialogflow API Admin*** role to it. Download the file in JSON format and place it in the `src` directory of the project —e.g. `src/secure/dialogflow_service_acct_key.json`. Then set `credentialsFile` property like so.

```js
app.use(
	new WebPlatform().use(
		new DialogflowNlu({
			credentialsFile: '../secure/dialogflow_service_acct_key.json'
		})
	),
    //... other plugins
)
```

# Testing Account Linking from Chatbot

Ideally, the web application should sign in on its own. Then, the `quantum.JovoDialogue` component included in this project uses
`kony.sdk.getDefaultInstance().currentClaimToken` to get the claims token and pass it in each request to the Jovo app.

**Note:** I would have liked to send this as a header, but I've found no way to send a custom header from Jovo's `JovoWebClient` class,... and no way to read it from the Jovo app anyway.

At the time of writing this, the Visualizer Preview is failing to initialise the SDK correctly. I'm not sure why so, as a hack, open the debugger console and run this.

```js
this.location="http://localhost:9989/JovoPoC/kdw#_ChatForm"
new kony.sdk().init("jovopoc", "jovopoc12345", "https://100032668.auth.konycloud.com/appconfig", ()=>{alert("done")}, (e)=>{alert(e)})
kony.sdk.getDefaultInstance().getIdentityService("IronBankAuthN").login({userid: "jon.snow@foo.com", password: "Test!12345"}, ()=>{alert("done")}, ()=>{alert("error")})
kony.sdk.getDefaultInstance().currentClaimToken
```
